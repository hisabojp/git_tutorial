{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "name": "0_1_tensorqs_tutorial_js.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrcFW8fIpIdD"
      },
      "source": [
        "「PyTorch入門  1. テンソル」\n",
        "===============================================================\n",
        "【原題】TENSORS\n",
        "\n",
        "【原著】\n",
        "[Suraj Subramanian](https://github.com/suraj813)、[Seth Juarez](https://github.com/sethjuarez/) 、[Cassie Breviu](https://github.com/cassieview/) 、[Dmitry Soshnikov](https://soshnikov.com/)、[Ari Bornstein](https://github.com/aribornstein/)\n",
        "\n",
        "\n",
        "【元URL】https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html\n",
        "\n",
        "【翻訳】電通国際情報サービスISID AIトランスフォーメーションセンター　小川 雄太郎\n",
        "\n",
        "【日付】2021年03月20日\n",
        "\n",
        "【チュトーリアル概要】\n",
        "\n",
        "本チュートリアルでは、PyTorchの基本データ型である、Tensor（テンソル）について解説を行います。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qP43GdSypjIh"
      },
      "source": [
        "テンソル：Tensors\n",
        "==========================\n",
        "\n",
        "テンソルは特殊なデータ構造で、配列や行列によく似ています。\n",
        "\n",
        "PyTorchではテンソル型の変数を使用して、モデルの入力と出力、そしてモデルのパラメータを表現します。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5c9yTQpp9pP"
      },
      "source": [
        "テンソルは[NumPy](https://numpy.org/)のndarraysに似ていますが、違いとしてGPUや他のハードウェアアクセラレータ上で動作させることができます。\n",
        "\n",
        "テンソルとNumPyの配列は基本的には同じメモリを共有することができるため、2つの型間での変換時にはデータをコピーする必要がありません。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mczXVnIbqslq"
      },
      "source": [
        "\n",
        "テンソルはその他に、自動微分に最適化されています（この点については、後ほど5. 自動微分にて、詳しく説明します）。\n",
        "\n",
        "NumPyのndarraysに慣れている人は、Tensor APIをすぐに使いこなせると思います。\n",
        "\n",
        "そうでない場合には、本チュートリアルを通してぜひ習得してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D68ZUMDoo65Z"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oOJ0Pj1o65h"
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNpNfUJDqwhg"
      },
      "source": [
        "テンソルの初期化\n",
        "=======================\n",
        "\n",
        "テンソルは様々な手法で初期化できます。\n",
        "\n",
        "以下に例を示します。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gD6xIZDhrEvF"
      },
      "source": [
        "**データから直接テンソルに変換**\n",
        "\n",
        "データから直接テンソルを作ることができます。\n",
        "\n",
        "その際、データ型は自動的に推測されます。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Zo-5JUco65i"
      },
      "source": [
        "data = [[1, 2],[3, 4]]\n",
        "x_data = torch.tensor(data)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i4Re_DCo65j"
      },
      "source": [
        "**NumPy arrayからテンソルに変換**\n",
        "\n",
        "テンソルとNumpy arraysは相互に変換可能です。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SErVsUQmo65k"
      },
      "source": [
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIwtzI63o65k"
      },
      "source": [
        "**他のテンソルから作成**\n",
        "\n",
        "他のテンソルから新しいテンソルを作成する場合、明示的に上書きされない限り、引数のテンソルのプロパティ（形状、データ型）を保持します。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9AX5RQZo65l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27868dca-d7d5-46bb-a34c-ce1893ae37e4"
      },
      "source": [
        "x_ones = torch.ones_like(x_data) # x_dataの特性（プロパティ）を維持\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # x_dataのdatatypeを上書き更新\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.1882, 0.7842],\n",
            "        [0.0655, 0.1804]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smW9ouQZo65l"
      },
      "source": [
        "**ランダム値や定数のテンソルの作成**\n",
        "\n",
        "\n",
        "``shape``は、テンソルの次元を示すタプルです。\n",
        "\n",
        "以下の例では、shapeからテンソルのサイズを決めています。\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrHFyTYCo65m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d89f5e4c-c96b-4c8b-c7d2-a34a9b1e1d64"
      },
      "source": [
        "shape = (2,3,)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.8846, 0.1635, 0.5570],\n",
            "        [0.0902, 0.0515, 0.4727]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzjHNug-o65m"
      },
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX4udb5ao65n"
      },
      "source": [
        "テンソルの属性変数\n",
        "==================\n",
        "\n",
        "\n",
        "テンソルは属性変数として、その形状、データの型、保存されているデバイスを保持しています。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXMqBDEXo65n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7e4cf97-9224-4788-b81b-59369caf78fb"
      },
      "source": [
        "tensor = torch.rand(3,4)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfBIS-6Eo65o"
      },
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6hnnVOCo65o"
      },
      "source": [
        "テンソルの操作\n",
        "==================\n",
        "\n",
        "PyTorchでは、算術、線形代数、行列操作（転置、インデックス、スライス）など、100種類以上のテンソル演算が可能です。\n",
        "\n",
        "種々操作の詳細は[こちら]((https://pytorch.org/docs/stable/torch.html)\n",
        ")をご覧ください。\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAwgHWRMnQNf"
      },
      "source": [
        "\n",
        "各操作はGPU上で実行可能です（一般的にCPUの場合より高速です）。\n",
        "\n",
        "\n",
        "Google Colaboratoryを使用している場合は、GPUを使用できるように設定してください。\n",
        "\n",
        "（Runtime > Change runtime type > GPU）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrGlCnhttGc4"
      },
      "source": [
        "デフォルトではテンソルはCPU上で作られます。\n",
        "\n",
        "そのため、明示的に、``.to``メソッドを使用して、テンソルをGPU上へと移動させます。\n",
        "\n",
        "大きなテンソルをデバイス間でコピーすると、時間とメモリの面でコストがかかる点にご注意ください。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6_nStSgo65o"
      },
      "source": [
        "# GPUが使用可能であれば、GPU上にテンソルを移動させる\n",
        "if torch.cuda.is_available():\n",
        "  tensor = tensor.to('cuda')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syaRBPBho65p"
      },
      "source": [
        "テンソル操作の中からいくつかを試してみましょう。\n",
        "\n",
        "NumPy APIに慣れていれば、Tensor APIも簡単に使えるようになると思います。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u3kTw8to65p"
      },
      "source": [
        "**numpy-likeなindexingとslicing:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OF85To5o65p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03d393e7-d195-41b6-eeae-339918f7ac38"
      },
      "source": [
        "tensor = torch.ones(4, 4)\n",
        "print('First row: ',tensor[0])\n",
        "print('First column: ', tensor[:, 0])\n",
        "print('Last column:', tensor[..., -1])\n",
        "tensor[:,1] = 0\n",
        "print(tensor)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First row:  tensor([1., 1., 1., 1.])\n",
            "First column:  tensor([1., 1., 1., 1.])\n",
            "Last column: tensor([1., 1., 1., 1.])\n",
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHWwoi5wo65p"
      },
      "source": [
        "**テンソルの結合**\n",
        "\n",
        "\n",
        "``torch.cat``を使用することで、テンソルを特定の次元に沿って結合させることができます（詳細は[こちら](https://pytorch.org/docs/stable/generated/torch.stack.html)をご覧ください）。\n",
        "\n",
        "``torch.cat``とは微妙に異なるテンソル結合演算である[``torch.stack``](https://pytorch.org/docs/stable/generated/torch.stack.html)も確認しておいてください。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS0A8qYao65q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ab01dc1-2378-4bd3-9948-366d19990746"
      },
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVuoj3lDo65q"
      },
      "source": [
        "**算術演算**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L00SHkoMo65q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e218ffc-42d8-437a-e09b-46a1a2728248"
      },
      "source": [
        "# 2つのテンソル行列のかけ算です。 y1, y2, y3 は同じ結果になります。\n",
        "y1 = tensor @ tensor.T\n",
        "y2 = tensor.matmul(tensor.T)\n",
        "\n",
        "y3 = torch.rand_like(tensor)\n",
        "torch.matmul(tensor, tensor.T, out=y3)\n",
        "\n",
        "\n",
        "# こちらは、要素ごとの積を求めます。 z1, z2, z3 は同じ値になります。\n",
        "z1 = tensor * tensor\n",
        "z2 = tensor.mul(tensor)\n",
        "\n",
        "z3 = torch.rand_like(tensor)\n",
        "torch.mul(tensor, tensor, out=z3)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCjumJ0uo65r"
      },
      "source": [
        "**1要素のテンソル**\n",
        "\n",
        "1要素のテンソル（テンソルの全要素を足し算する等をした結果生まれます）を扱う場合には、``.item()``を使用することでPythonの数値型変数に変換できます。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrA8pq1Jo65r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87a8cf0f-73e7-49c7-c903-349ce6cff7d9"
      },
      "source": [
        "agg = tensor.sum()\n",
        "agg_item = agg.item()\n",
        "print(agg_item, type(agg_item))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12.0 <class 'float'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeM8WbzUo65s"
      },
      "source": [
        "**インプレース操作**\n",
        "\n",
        "\n",
        "演算結果をオペランドに格納する演算をインプレースと呼びます。\n",
        "\n",
        "メソッドの最後、接尾辞として操作名に、 ``_`` が付きます。\n",
        "\n",
        "例えば、``x.copy_(y)``, ``x.t_()``であり、``x``の内容そのものを更新します。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQCoq-t6o65s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09dece05-0517-4ef1-fe2e-41986c54d239"
      },
      "source": [
        "print(tensor, \"\\n\")\n",
        "tensor.add_(5)\n",
        "print(tensor)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n",
            "tensor([[6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzahS3_ho65s"
      },
      "source": [
        "【注意】\n",
        "\n",
        "\n",
        "インプレース操作はメモリを節約できますが、演算履歴が失われてしまうため、微分を計算する際には問題となります。\n",
        "\n",
        "そのため、そのような微分を求める場面ではインプレース操作の使用は推奨されていません。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3TyDfUoo65t"
      },
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-KDP7cFo65t"
      },
      "source": [
        "NumPyとの変換\n",
        "=========================\n",
        "\n",
        "CPU上のテンソルとNumpy arraysは同じメモリを共有することができ、相互変換が容易です。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tmbb956fo65t"
      },
      "source": [
        "**Tensor to NumPy array**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlExSMGso65u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c67cee69-caa1-4d98-8dfe-55f68db2594f"
      },
      "source": [
        "t = torch.ones(5)\n",
        "print(f\"t: {t}\")\n",
        "n = t.numpy()\n",
        "print(f\"n: {n}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([1., 1., 1., 1., 1.])\n",
            "n: [1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyPjEJA6o65u"
      },
      "source": [
        "この際、テンソルが変化すると、Numpy側も変化します。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SuCn_Lro65v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e9a5ca7-d981-414a-f37e-2cffffbb2cf2"
      },
      "source": [
        "t.add_(1)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t: tensor([2., 2., 2., 2., 2.])\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rc7EbiQco65w"
      },
      "source": [
        "**NumPy array to Tensor**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbrBK5x3o65w"
      },
      "source": [
        "n = np.ones(5)\n",
        "t = torch.from_numpy(n)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD4gRgwio65w"
      },
      "source": [
        "NumPy arrayの変化はテンソル側にも反映されます。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEjB9iMJo65w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eddef214-5e76-488a-ba7f-4311f461ecd6"
      },
      "source": [
        "np.add(n, 1, out=n)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdocpOeVwstC"
      },
      "source": [
        "以上。"
      ]
    }
  ]
}