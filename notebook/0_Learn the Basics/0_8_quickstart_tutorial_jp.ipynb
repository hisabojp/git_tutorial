{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "name": "0_8_quickstart_tutorial_jp.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euViW0W_QZ39"
      },
      "source": [
        "「PyTorch入門  8. クイックスタート」\n",
        "===============================================================\n",
        "【原題】Learn the Basics\n",
        "\n",
        "【原著】\n",
        "[Suraj Subramanian](https://github.com/suraj813)、[Seth Juarez](https://github.com/sethjuarez/) 、[Cassie Breviu](https://github.com/cassieview/) 、[Dmitry Soshnikov](https://soshnikov.com/)、[Ari Bornstein](https://github.com/aribornstein/)\n",
        "\n",
        "\n",
        "【元URL】https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
        "\n",
        "【翻訳】電通国際情報サービスISID AIトランスフォーメーションセンター　小川 雄太郎\n",
        "\n",
        "【日付】2021年03月20日\n",
        "\n",
        "【チュトーリアル概要】\n",
        "\n",
        "本チュートリアルでは、機械学習を実行するためのPyTorchの各APIを紹介します。詳細を知りたい方は、各セクションのリンク先をご参照ください。\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgLidedEc2b-"
      },
      "source": [
        "【注意】\n",
        "\n",
        "ディープラーニングフレームワークの経験があり、ディープラーニングの実装に慣れている方は、本チュートリアルをまず確認し、PyTorchのAPIに慣れてください。\n",
        "\n",
        "<br>\n",
        "\n",
        "ディープラーニングフレームワークを利用した実装に初めて取り組む方は、本チュートリアルからではなく、\n",
        "\n",
        "[「PyTorch入門  1. テンソル」](https://colab.research.google.com/github/YutaroOgawa/pytorch_tutorials_jp/blob/main/notebook/0_Learn%20the%20Basics/1_1_tensor_tutorial_jp.ipynb)から、1 stepずつ進めてください。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsEK0E7XJRQp"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-m_8vo5Q_PM"
      },
      "source": [
        "データの取り扱い\n",
        "-----------------\n",
        "\n",
        "PyTorchではデータを取り扱う際に、基本的な要素が2つ存在します。\n",
        "\n",
        "``torch.utils.data.Dataset``と``torch.utils.data.DataLoader``です。\n",
        "\n",
        "<br>\n",
        "\n",
        "``Dataset`` は各ラベルと、それに対応するサンプルデータを保持します。\n",
        "\n",
        "``DataLoader`` は``Dataset``をイテレーティブに（＝反復処理可能に）操作できるようラップしたものになります。\n",
        "\n",
        "<br>\n",
        "\n",
        "（詳細）\n",
        "https://pytorch.org/docs/stable/data.html\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqk7kamjPaHz"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn86OXeoPaH8"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V45G3n3ljabV"
      },
      "source": [
        "PyTorchには以下に示すようなドメイン固有のライブラリが存在し、それぞれにデータセットが用意されています。\n",
        "\n",
        "\n",
        "本チュートリアルでは、TorchVisionのデータセットを使用します。\n",
        "\n",
        "- [TorchText](https://pytorch.org/text/stable/index.html)\n",
        "- [TorchVision](https://pytorch.org/vision/stable/index.html)\n",
        "- [TorchAudio](https://pytorch.org/audio/stable/index.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o78mnLW3j4rS"
      },
      "source": [
        "``torchvision.datasets`` モジュールには、画像データの ``Dataset`` オブジェクトがたくさん用意されています。\n",
        "\n",
        "例えば、CIFAR, COCOなどです ([データセット一覧はこちらから](https://pytorch.org/docs/stable/torchvision/datasets.html))。\n",
        "\n",
        "本チュートリアルでは、FashionMNISTデータセットを使用します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1HhfyQAkYCW"
      },
      "source": [
        "TorchVisionの すべての``Dataset`` には2つの引数があります。\n",
        "\n",
        "``transform`` と ``target_transform`` であり、それぞれサンプルとラベルの変換処理を行います。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUaIJI6OPaH-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03950ba6-0ac1-4cea-bb64-16bcd7f37973"
      },
      "source": [
        "# 訓練データをdatasetsからダウンロード\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# テストデータをdatasetsからダウンロード\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 11.9MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 173kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.11MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 21.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfVm1SIvlB3E"
      },
      "source": [
        "DataLoaderの引数としてDatasetを渡します。\n",
        "\n",
        "\n",
        "DataLoaderはDatasetをイテレート処理できるようにラップしたものです。\n",
        "\n",
        "バッチ処理、サンプリング、シャッフル、マルチプロセスでのデータ読み込み等をサポートしています。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b16dZow40D0V"
      },
      "source": [
        "以下では、バッチサイズを64と定義します。\n",
        "\n",
        "つまり、データローダの反復要素は、64個の特徴量とラベルから構成されるバッチを返すことになります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mQ7suUpPaH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5739d32-2855-492f-b73d-c1f6c490cc10"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "# データローダーの作成\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
        "    print(\"Shape of y: \", y.shape, y.dtype)\n",
        "    break"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
            "Shape of y:  torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZXNVnJNPaH_"
      },
      "source": [
        "さらなる詳細は、[「PyTorch入門  2. データセットとデータローダー」](https://colab.research.google.com/github/YutaroOgawa/pytorch_tutorials_jp/blob/main/notebook/0_Learn%20the%20Basics/0_2_data_tutorial_jp.ipynb\n",
        ")をご覧ください。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3eETwIfPaH_"
      },
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cK3051oMPaIA"
      },
      "source": [
        "モデルの構築\n",
        "------------------\n",
        "\n",
        "PyTorchでニューラルネットワークの形を定義する際には、[nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)を継承します。\n",
        "\n",
        "\n",
        "``__init__`` 関数で、ネットワークの各レイヤーを定義し、データの順伝搬を``forward`` 関数に定義します。\n",
        "\n",
        "なお処理を高速化するために、可能であればニューラルネットワークをGPU上へ移動させます。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxiGClK2PaIA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71024882-4bfd-4ae9-ed43-e4d5afa4a19f"
      },
      "source": [
        "# 訓練に際して、可能であればGPU（cuda）を設定します。GPUが搭載されていない場合はCPUを使用します\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))\n",
        "\n",
        "# modelを定義します\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AozARAXuPaIA"
      },
      "source": [
        "\n",
        "さらなる詳細は、[「PyTorch入門 4. モデル構築」](https://colab.research.google.com/github/YutaroOgawa/pytorch_tutorials_jp/blob/main/notebook/0_Learn%20the%20Basics/0_4_buildmodel_tutorial_js.ipynb\n",
        ")をご覧ください。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTdss5_lPaIA"
      },
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyONjE_RPaIB"
      },
      "source": [
        "モデルパラメータの最適化\n",
        "----------------------------------------\n",
        "\n",
        "ニューラルネットワークモデルを訓練するためには、\n",
        "\n",
        "損失関数：[loss function](<https://pytorch.org/docs/stable/nn.html#loss-functions)と、最適化手法：[optimizer](https://pytorch.org/docs/stable/optim.html)が必要です。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUhxZFrWPaIB"
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQhc_wtvPaIC"
      },
      "source": [
        "1回の訓練ループにおいてモデルは、まず訓練データのバッチに対して推論を実行して損失誤差を計算し、\n",
        "\n",
        "その後、損失誤差をバックプロパゲーションして、モデルパラメータを更新します。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnqyJyp9PaIC"
      },
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # 損失誤差を計算\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # バックプロパゲーション\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ohot83GBPaID"
      },
      "source": [
        "また、モデルがうまく学習していることを確認するために、テストデータセットに対するモデルの性能も確認します。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxUT7hOJPaID"
      },
      "source": [
        "def test(dataloader, model):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= size\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmcUJgG9PaIE"
      },
      "source": [
        "訓練プロセスでは複数イテレーションを実行します。\n",
        "\n",
        "各エポックの間、モデルはより良い予測ができるようにパラメータを学習します。\n",
        "\n",
        "エポックごとにモデルの正解率と損失を出力して、正解率が向上し、損失が低下していっているかを確認します。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UklgW5aBPaIF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f42d5103-74fc-4b19-b594-27457dc4818f"
      },
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model)\n",
        "print(\"Done!\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.307403  [    0/60000]\n",
            "loss: 2.305990  [ 6400/60000]\n",
            "loss: 2.297464  [12800/60000]\n",
            "loss: 2.285618  [19200/60000]\n",
            "loss: 2.291329  [25600/60000]\n",
            "loss: 2.281654  [32000/60000]\n",
            "loss: 2.290183  [38400/60000]\n",
            "loss: 2.284681  [44800/60000]\n",
            "loss: 2.272899  [51200/60000]\n",
            "loss: 2.242026  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 23.0%, Avg loss: 0.035480 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.282821  [    0/60000]\n",
            "loss: 2.283646  [ 6400/60000]\n",
            "loss: 2.261442  [12800/60000]\n",
            "loss: 2.235323  [19200/60000]\n",
            "loss: 2.244049  [25600/60000]\n",
            "loss: 2.245418  [32000/60000]\n",
            "loss: 2.237929  [38400/60000]\n",
            "loss: 2.244912  [44800/60000]\n",
            "loss: 2.220443  [51200/60000]\n",
            "loss: 2.152840  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 32.4%, Avg loss: 0.034547 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 2.246159  [    0/60000]\n",
            "loss: 2.251995  [ 6400/60000]\n",
            "loss: 2.214083  [12800/60000]\n",
            "loss: 2.161076  [19200/60000]\n",
            "loss: 2.177092  [25600/60000]\n",
            "loss: 2.199604  [32000/60000]\n",
            "loss: 2.163105  [38400/60000]\n",
            "loss: 2.191411  [44800/60000]\n",
            "loss: 2.152137  [51200/60000]\n",
            "loss: 2.034687  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 31.6%, Avg loss: 0.033327 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 2.201386  [    0/60000]\n",
            "loss: 2.212322  [ 6400/60000]\n",
            "loss: 2.157824  [12800/60000]\n",
            "loss: 2.066565  [19200/60000]\n",
            "loss: 2.095909  [25600/60000]\n",
            "loss: 2.148028  [32000/60000]\n",
            "loss: 2.071711  [38400/60000]\n",
            "loss: 2.131096  [44800/60000]\n",
            "loss: 2.075142  [51200/60000]\n",
            "loss: 1.904448  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 31.6%, Avg loss: 0.032058 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 2.151202  [    0/60000]\n",
            "loss: 2.167140  [ 6400/60000]\n",
            "loss: 2.102355  [12800/60000]\n",
            "loss: 1.977811  [19200/60000]\n",
            "loss: 2.017390  [25600/60000]\n",
            "loss: 2.100112  [32000/60000]\n",
            "loss: 1.979457  [38400/60000]\n",
            "loss: 2.071594  [44800/60000]\n",
            "loss: 2.001752  [51200/60000]\n",
            "loss: 1.791701  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 33.2%, Avg loss: 0.030967 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zegYqVDmPaIF"
      },
      "source": [
        "さらなる詳細は、[「PyTorch入門 6. 最適化」](https://colab.research.google.com/github/YutaroOgawa/pytorch_tutorials_jp/blob/main/notebook/0_Learn%20the%20Basics/0_6_optimization_tutorial_js.ipynb)をご覧ください。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifTK5jw-PaIF"
      },
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW_NWdd_PaIF"
      },
      "source": [
        "モデルの保存\n",
        "-------------\n",
        "\n",
        "モデルを保存する一般的な方法は、モデルの内部状態の辞書（モデルのパラメータを含む）をシリアル化する手法です。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-REQmU_PaIG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "225a3865-9303-4e3f-ba4f-1306e15e67ff"
      },
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmJUrj9QKwDr"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVBQU1xuPaIG"
      },
      "source": [
        "モデルの読み込み\n",
        "----------------------------\n",
        "\n",
        "モデルの読み込む際には、まずモデルの構造を再作成し、そのインスタンスに、保存しておいた状態辞書をロードします。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8b7_8iVPaIG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75017076-12b7-46b0-fa30-d81df5950a9c"
      },
      "source": [
        "model = NeuralNetwork()\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6hRRk6RPaIG"
      },
      "source": [
        "これでモデルは推論可能な状態です。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njDxPrS1PaIH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee423b89-55a3-46e5-8294-a34976d6714a"
      },
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Sneaker\", Actual: \"Ankle boot\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1v8RC77ZPaIH"
      },
      "source": [
        "さらなる詳細は、[「PyTorch入門 7. モデルの保存・読み込み」](https://colab.research.google.com/github/YutaroOgawa/pytorch_tutorials_jp/blob/main/notebook/0_Learn%20the%20Basics/0_7_saveloadrun_tutorial_js.ipynb)をご覧ください。\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKOVE9zszN7z"
      },
      "source": [
        "以上。"
      ]
    }
  ]
}